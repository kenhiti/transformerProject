# Transformer Architecture

This project is a proof of concept about Deep Learning, specifically demonstrating an implementation of the Transformer Architecture and Attention Mechanism. 

I used an article called Attention is all you need when referring to this one.

The first step is to [download](https://www.statmt.org/europarl/v7/pt-en.tgz) these files and extract them to folder "/utils/files/input".

All dependencies are listed in file requirements.txt

Below are some useful references:

* [FastAPI](https://fastapi.tiangolo.com/)
* [Uvicorn](https://www.uvicorn.org/) 
* [Tensorflow](https://www.tensorflow.org/)


